---
title: "Day 11: Inference for difference in means from two independent samples and Power (Sections 5.3, 5.4)"
subtitle: "BSTA 511/611"
author: "Meike Niederhausen, PhD"
institute: "OHSU-PSU School of Public Health"
date: "11/11/2024"
categories: ["Week 7"]
format: 
  html:
    link-external-newwindow: true
    toc: true
execute:
  echo: true
  freeze: auto  # re-render only when source changes
# editor: visual
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: "setup"
#| include: false
knitr::opts_chunk$set(echo = TRUE, fig.height=3, fig.width=5, message = F)
```

## Load packages

* Packages need to be loaded _every time_ you restart R or render an Qmd file

```{r}
# run these every time you open Rstudio
library(tidyverse)    
library(oibiostat)
library(janitor)
library(rstatix)
library(knitr)
library(gtsummary)
library(moderndive)
library(gt)
library(broom) # new-ish
library(here) # new-ish
library(pwr) # NEW!!

```


- You can check whether a package has been loaded or not 
  - by looking at the Packages tab and 
  - seeing whether it has been checked off or not



## MoRitz's tip of the day

Add tabbed sections to your html file using `tabset`.

::: panel-tabset

### First tab

* You can make subsections appear as different tabs in your html file.
* This is the first tab.
* It was created by adding `::: panel-tabset` right above the subsection `### First tab` ([see the code file]{style="color:green"}). 
* Look up to the right of where it says "First tab," and you will see a second tab with the creative name "Second tab."
* If you are viewing the html output of this file, you can click on the different tabs to see what's in them.
* To stop new tabs from being created, close off the original `::: panel-tabset` command with `:::` at the end.
    * In the code file, you will see the `:::` at the end of the `### Read up on tabsets` tab.


### Second tab

* Welcome to the second tab! 

![](/img_slides/mimi_normal_IMG_4244.png){fig-align="center"}

### Read up on tabsets

* You can read up more about creating tabs at
  * <https://quarto.org/docs/interactive/layout.html#tabset-panel>

```{=html}
<iframe width="800" height="300" src="https://quarto.org/docs/interactive/layout.html#tabset-panel" title="Webpage example"></iframe>
```

If you are reading the source code file, the next line contains `:::`, which closes the tabsets. 
:::


# Where are we?

CI's and hypothesis tests for different scenarios:

$$\text{point estimate} \pm z^*(or~t^*)\cdot SE,~~\text{test stat} = \frac{\text{point estimate}-\text{null value}}{SE}$$

Day | Book | Population <br> parameter | Symbol | Point estimate | Symbol | SE
--|--|--|--|--|--|--
10 | 5.1 | Pop mean | $\mu$ | Sample mean | $\bar{x}$ | $\frac{s}{\sqrt{n}}$
10 | 5.2 | Pop mean of paired diff | $\mu_d$ or $\delta$ | Sample mean of paired diff | $\bar{x}_{d}$  | **$\frac{s_d}{\sqrt{n}}$**
11 | 5.3 | [Diff in pop <br> means]{style="color:green"} | [$\mu_1-\mu_2$]{style="color:green"} | [Diff in sample <br> means]{style="color:green"} | [$\bar{x}_1 - \bar{x}_2$]{style="color:green"}  | [**???**]{style="color:red"}
12 | 8.1 | Pop proportion | $p$ | Sample prop | $\widehat{p}$  |
12 | 8.2 | Diff in pop <br> proportions | $p_1-p_2$ | Diff in sample <br> proportions | $\widehat{p}_1-\widehat{p}_2$ |


## Goals for today (Section 5.3)

* Statistical inference for difference in means from 2 independent samples
    1. What are $H_0$ and $H_a$?
    
    1. What is the SE for $\bar{x}_1 - \bar{x}_2$?
    
    1. Hypothesis test
    
    1. Confidence Interval
    
    1. Run test in R - using long vs. wide data
    
    1. Satterthwaite's df
    
    1. Pooled SD


## Examples of designs with two independent samples

* Any study where participants are randomized to a control and treatment group

* Study where create two groups based on whether they were exposed or not to some condition (can be observational)

*  Book: "Does treatment using embryonic stem cells (ESCs) help improve heart function following a heart attack?"

*  Book: "Is there evidence that newborns from mothers who smoke have a different average birth weight than newborns from mothers who do not smoke?"


* _The key is that the data from the two groups are independent of each other._


## Steps in a Hypothesis Test

1. Set the __[level of significance]{style="color:darkorange"}__ $\alpha$

1. Specify the __[null]{style="color:darkorange"}__ ( $H_0$ ) and __[alternative]{style="color:darkorange"}__ ( $H_A$ ) __[hypotheses]{style="color:darkorange"}__
    1. In symbols
    1. In words
    1. Alternative: one- or two-sided?

1. Calculate the __[test statistic]{style="color:darkorange"}__. 

1. Calculate the __[p-value]{style="color:darkorange"}__ based on the observed test statistic and its sampling distribution

1. Write a __[conclusion]{style="color:darkorange"}__ to the hypothesis test
    1. Do we reject or fail to reject $H_0$?
    1. Write a conclusion in the context of the problem



# Does caffeine increase finger taps/min (on average)?

__Study Design__:

* 20 male college students students were trained to tap their fingers at a rapid rate.
* Each then drank 2 cups of coffee (double-blind)
    * __Control__ group: decaf
    * __Caffeine__ group: ~ 200 mg caffeine 
* After 2 hours, students were tested.
* __Taps/minute__ recorded

Hand, David J.; Daly, Fergus; McConway, K.; Lunn, D. and Ostrowski, E. (1993). [A handbook of small data sets](https://www.crcpress.com/A-Handbook-of-Small-Data-Sets/Hand-Daly-McConway-Lunn-Ostrowski/p/book/9780412399206). London, U.K.: Chapman and Hall.



* Load the data from the csv file `CaffeineTaps.csv`
* The code below is for when the data file is in a folder called `data` that is in your R project folder (your working directory)

```{r}
#| fig.width: 10
#| fig.height: 6
CaffTaps <- read_csv(here::here("data", "CaffeineTaps.csv"))

glimpse(CaffTaps)
```


## EDA: Explore the finger taps data

Dotplot of taps/minute stratified by group

```{r}
ggplot(CaffTaps, aes(x=Taps)) +
  geom_dotplot() +
  facet_wrap(vars(Group), ncol=1)
```

Summary statistics stratified by group

```{r}
# get_summary_stats() from rstatix package
sumstats <- CaffTaps %>% 
  group_by(Group) %>% 
  get_summary_stats(type = "mean_sd") 
sumstats %>% gt()
diff(sumstats$mean)
```



# Step 2: Null & Alternative Hypotheses 

* __Question__: Is there evidence to support that drinking caffeine increases the number of finger taps/min?

Null and alternative hypotheses in __words__

*Include as much context as possible*


* $H_0$: The population difference in mean finger taps/min between the caffeine and control groups is ... 

* $H_A$: The population difference in mean finger taps/min between the caffeine and control groups is ...


Null and alternative hypotheses in __symbols__

\begin{align}
H_0:& \mu_{caff} - \mu_{ctrl} = \\
H_A:& \mu_{caff} - \mu_{ctrl} \\
\end{align}



# Step 3: Test statistic (part 1)

Recall that in general the test statistic has the form:

$$\text{test stat} = \frac{\text{point estimate}-\text{null value}}{SE}$$
Thus, for a two sample independent means test, we have:

$$\text{test statistic} = \frac{\bar{x}_1 - \bar{x}_2 - 0}{SE_{\bar{x}_1 - \bar{x}_2}}$$

* What is the formula for $SE_{\bar{x}_1 - \bar{x}_2}$?
* What is the probability distribution of the test statistic?
* What assumptions need to be satisfied?


## What distribution does $\bar{X}_1 - \bar{X}_2$ have?


Let $\bar{X}_1$ and $\bar{X}_2$ be the means of random samples from two independent groups, with parameters:

|             | Group 1    | Group 2    |
|-------------|------------|------------|
| sample size | $n_1$      | $n_2$      |
| pop mean    | $\mu_1$    | $\mu_2$    |
| pop sd      | $\sigma_1$ | $\sigma_2$ |


Some theoretical statistics:

* If $\bar{X}_1$ and $\bar{X}_2$ are independent normal r.v.'s, then $\bar{X}_1 - \bar{X}_2$ is also normal
* What is the mean of $\bar{X}_1 - \bar{X}_2$? 

$$E[\bar{X}_1 - \bar{X}_2] = E[\bar{X}_1] - E[\bar{X}_2] = \mu_1-\mu_2$$

* What is the standard deviation of $\bar{X}_1 - \bar{X}_2$?

$$Var(\bar{X}_1 - \bar{X}_2) = Var(\bar{X}_1) + Var(\bar{X}_2) = \frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2} \\
SD(\bar{X}_1 - \bar{X}_2) = \sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}$$



## Step 3: Test statistic (part 2)


$$
t_{\bar{x}_1 - \bar{x}_2} = \frac{\bar{x}_1 - \bar{x}_2 - 0}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}
$$

* $\bar{x}_1, \bar{x}_2$ are the sample means
* $\mu_0=0$ is the mean value specified in $H_0$
* $s_1, s_2$ are the sample SD's
* $n_1, n_2$ are the sample sizes

* Statistical theory tells us that $t_{\bar{x}_1 - \bar{x}_2}$ follows a __student's t-distribution__ with 
    * $df \approx$ smaller of $n_1-1$ and $n_2-1$
    * this is a conservative estimate (smaller than actual $df$ )

__Assumptions__:

* __Independent observations & samples__
    * The observations were collected independently. 
    * In particular, the observations from the two groups were not paired in any meaningful way.
* __Approximately normal samples or big n's__ 
    * The distributions of the samples should be approximately normal 
    * _or_ _both_ their sample sizes should be at least 30.


## Step 3: Test statistic (part 3)


```{r}
#| echo: false
CaffTaps %>% group_by(Group) %>% get_summary_stats(type = "mean_sd") %>% gt()
```

$$
\text{test statistic} = t_{\bar{x}_1 - \bar{x}_2} = \frac{\bar{x}_1 - \bar{x}_2 - 0}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}
$$


```{r}
#| include: false
# 1: caffeine
# 2: no caffeine
n1 <- 10
n2 <- 10
(xbar1 <- sumstats$mean[1])
(xbar2 <- sumstats$mean[2])
(diff_x <- xbar1 - xbar2)
(sd1 <- sumstats$sd[1])
(sd2 <- sumstats$sd[2])
mu <- 0

(se <- sqrt(sd1^2/n1 + sd2^2/n2))
(tstat <- (diff_x - mu)/se)

alpha <- 0.05
(p_area <- 1-alpha/2)

1-pt(tstat, df=min(n1 -1, n2-1))
pt(tstat, df=min(n1 -1, n2-1), lower.tail = FALSE)

2*(1-pt(tstat, df=min(n1 -1, n2-1)))
```



<hr>

Based on the value of the test statistic, do you think we are going to reject or fail to reject $H_0$?


## Step "3b": Assumptions satisfied?

__Assumptions__:

* __Independent observations & samples__
    * The observations were collected independently. 
    * In particular, the observations from the two groups were not paired in any meaningful way.

* __Approximately normal samples or big n's__ 
    * The distributions of the samples should be approximately normal 
    * _or_ _both_ their sample sizes should be at least 30.

```{r}
ggplot(CaffTaps, aes(x=Taps)) +
  geom_dotplot() +
  facet_wrap(vars(Group), ncol=1)
```


The __[p-value]{style="color:darkorange"}__ is the __probability__ of obtaining a test statistic _just as extreme or more extreme_ than the observed test statistic assuming the null hypothesis $H_0$ is true. 


```{r}
# specify upper and lower bounds of shaded region below
mu <- 0
std <- se

# The following figure is only an approximation of the 
# sampling distribution since I used a normal instead
# of t-distribution to make it.

ggplot(data.frame(x = c(mu-5*std, mu+5*std)), aes(x = x)) + 
  stat_function(fun = dnorm, 
                args = list(mean = mu, sd = std)) + 
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks=c(mu, mu - 1*(1:5), mu + 1*(1:5))) +
  theme(axis.text.x=element_text(angle = -30, hjust = 0)) +
  labs(y = "", 
       x = "difference in means",
       title = "Sampling distribution of difference in means") +
  geom_vline(xintercept = c(diff_x), 
             color = "red")
```

```{r}
ggplot(data = data.frame(x = c(-5, 5)), aes(x)) + 
  stat_function(fun = dt, args = list(df = min(n1 -1, n2-1))) + 
  ylab("") + 
  xlab("t-dist with df = 9") +
  scale_y_continuous(breaks = NULL) + 
  scale_x_continuous(breaks=c(mu, mu - (1:5), mu + (1:5))) +
  geom_vline(xintercept = c(tstat), 
             color = "red")
```

Calculate the _p_-value:



# Step 5: Conclusion to hypothesis test

\begin{align}
H_0:& \mu_{caff} - \mu_{ctrl} = 0\\
H_A:& \mu_{caff} - \mu_{ctrl} > 0\\
\end{align}

* Recall the $p$-value = 0.00397
* Use $\alpha$ = 0.05.
* Do we reject or fail to reject $H_0$?

__Conclusion statement__:

* Stats class conclusion
    * There is sufficient evidence that the (population) difference in mean finger taps/min with vs. without caffeine is greater than 0 ( $p$-value = 0.004).

* More realistic manuscript conclusion: 
    * The mean finger taps/min were 244.8 (SD = 2.4) and 248.3 (SD = 2.2) for the control and caffeine groups, and the increase of 3.5 taps/min was statistically significant ( $p$-value = 0.004).


# 95% CI for the mean difference in cholesterol levels

```{r}
#| echo: false
CaffTaps %>% group_by(Group) %>% get_summary_stats(type = "mean_sd") %>% gt()
```

```{r}
#| include: false
# 1: caffeine
# 2: no caffeine
# n1 <- 10
# n2 <- 10
# (xbar1 <- sumstats$mean[1])
# (xbar2 <- sumstats$mean[2])
# (diff_x <- xbar1 - xbar2)
# (sd1 <- sumstats$sd[1])
# (sd2 <- sumstats$sd[2])
# mu <- 0
# 
# (se <- sqrt(sd1^2/n1 + sd2^2/n2))
# (tstat <- (diff_x - mu)/se)
# 
# 1-pt(tstat, df=min(n1 -1, n2-1))
# pt(tstat, df=min(n1 -1, n2-1), lower.tail = FALSE)
# 
# 2*(1-pt(tstat, df=min(n1 -1, n2-1)))
alpha <- 0.05
(p_area <- 1-alpha/2)

(tstar <- qt(p_area, df=min(n1 -1, n2-1))) 
# (se <- sqrt(sd1^2/n1 + sd2^2/n2))
(moe <- tstar * se) 
(LB <- diff_x - moe)
(UB <- diff_x + moe)
```


CI for $\mu_{caff} - \mu_{ctrl}$:

$$\bar{x}_{caff} - \bar{x}_{ctrl} \pm t^* \cdot \sqrt{\frac{s_{caff}^2}{n_{caff}}+\frac{s_{ctrl}^2}{n_{ctrl}}}$$


__Interpretation__:  
We are 95% confident that the (population) difference in mean finger taps/min between the caffeine and control groups is between `r round(LB, 3)` mg/dL and `r round(UB, 3)` mg/dL.

* _Based on the CI, is there evidence that drinking caffeine made a difference in finger taps/min? Why or why not?_

# R

## R: 2-sample t-test (with long data)

* The `CaffTaps` data are in a *long* format, meaning that 
    * all of the outcome values are in one column and 
    * another column indicates which group the values are from
* This is a common format for data from multiple samples, especially if the sample sizes are different.


```{r}
(Taps_2ttest <- t.test(formula = Taps ~ Group, alternative = "greater", data = CaffTaps))
```


### `tidy` the `t.test` output


```{r}
# use tidy command from broom package for briefer output that's a tibble
tidy(Taps_2ttest) %>% gt()
```

* Pull the p-value:

```{r}
tidy(Taps_2ttest)$p.value  # we can pull specific values from the tidy output
```


## R: 2-sample t-test (with wide data)


```{r}
# make CaffTaps data wide: pivot_wider needs an ID column so that it 
# knows how to "match" values from the Caffeine and NoCaffeine groups
CaffTaps_wide <- CaffTaps %>% 
  mutate(id = rep(1:10, 2)) %>% #  "fake" IDs for pivot_wider step
  pivot_wider(names_from = "Group",
              values_from = "Taps")
glimpse(CaffTaps_wide)

t.test(x = CaffTaps_wide$Caffeine, y = CaffTaps_wide$NoCaffeine, alternative = "greater") %>% 
  tidy() %>% gt()
```


## Why are the df's in the R output different?

From many slides ago:

* Statistical theory tells us that $t_{\bar{x}_1 - \bar{x}_2}$ follows a __student's t-distribution__ with 
    * $df \approx$ smaller of $n_1-1$ and $n_2-1$
    * this is a __conservative__ estimate (smaller than actual $df$ )

The actual degrees of freedom are calculated using  Satterthwaite's method:

$$\nu = \frac{[ (s_1^2/n_1) + (s_2^2/n_2) ]^2}
{(s_1^2/n_1)^2/(n_1 - 1) + (s_2^2/n_2)^2/(n_2-1) }
= \frac{ [ SE_1^2 + SE_2^2 ]^2}{ SE_1^4/df_1 + SE_2^4/df_2 }$$

<hr>

Verify the _p_-value in the R output using $\nu$ = 17.89012:

```{r}
pt(3.3942, df = 17.89012, lower.tail = FALSE)
``` 


# Pooled standard deviation estimate

* Sometimes we have reasons to believe that the population SD's from the two groups are equal, such as when randomizing participants to two groups


* In this case we can use a __pooled SD__:

$$s_{pooled}^2 = \frac{s_1^2 (n_1-1) + s_2^2 (n_2-1)}{n_1 + n_2 - 2}$$
where 

* $n_1$, $n_2$ are the sample sizes, and
* $s_1$, $s_2$ are the sample standard deviations 
* of the two groups

* We use the pooled SD instead of $s_1^2$ and $s_2^2$ when calculating the standard error 

$$SE = \sqrt{\frac{s_{pooled}^2}{n_1} + \frac{s_{pooled}^2}{n_2}}= s_{pooled}\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}$$



__Test statistic__ with pooled SD:

$$t_{\bar{x}_1 - \bar{x}_2} = \frac{\bar{x}_1 - \bar{x}_2 -0}{s_{pooled}\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}$$

__CI__  with pooled SD:

$$(\bar{x}_1 - \bar{x}_2) \pm t^{\star} \cdot s_{pooled} \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}$$

* The $t$ distribution degrees of freedom are now:
$$df = (n_1 - 1) + (n_2 - 1) = n_1 + n_2 - 2.$$



## R: 2-sample t-test with pooled SD 

```{r}
# t-test with pooled SD
t.test(formula = Taps ~ Group, alternative = "greater", 
       var.equal = TRUE,  # pooled SD 
       data = CaffTaps) %>% tidy() %>% gt()

# t-test without pooled SD
t.test(formula = Taps ~ Group, alternative = "greater", 
       var.equal = FALSE,  # default, NOT pooled SD 
       data = CaffTaps) %>% tidy() %>% gt()
```

Similar output in this case - why??


# What's next? 

CI's and hypothesis tests for different scenarios:

$$\text{point estimate} \pm z^*(or~t^*)\cdot SE,~~\text{test stat} = \frac{\text{point estimate}-\text{null value}}{SE}$$

Day | Book | Population <br> parameter | Symbol | Point estimate | Symbol | SE
--|--|--|--|--|--|--
10 | 5.1 | Pop mean | $\mu$ | Sample mean | $\bar{x}$ | $\frac{s}{\sqrt{n}}$
10 | 5.2 | Pop mean of paired diff | $\mu_d$ or $\delta$ | Sample mean of paired diff | $\bar{x}_{d}$  | **$\frac{s_d}{\sqrt{n}}$**
11 | 5.3 | [Diff in pop <br> means]{style="color:green"} | [$\mu_1-\mu_2$]{style="color:green"} | [Diff in sample <br> means]{style="color:green"} | [$\bar{x}_1 - \bar{x}_2$]{style="color:green"}  | [**$\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}$ or pooled**]{style="color:red"}
12 | 8.1 | [Pop proportion]{style="color:darkblue"} | [$p$]{style="color:darkblue"} | [Sample prop]{style="color:darkblue"} | [$\widehat{p}$]{style="color:darkblue"}  | [**???**]{style="color:red"}
12 | 8.2 | [Diff in pop <br> proportions]{style="color:darkblue"} | [$p_1-p_2$]{style="color:darkblue"} | [Diff in sample <br> proportions]{style="color:darkblue"} | [$\widehat{p}_1-\widehat{p}_2$]{style="color:darkblue"} | [**???**]{style="color:red"}


# Power and sample size calculations

* Critical values & rejection region
* Type I & II errors
* Power
* How to calculate sample size needed for a study?

<hr>

* Materials are from 
    * __Section 4.3.4__ Decision errors
    * __Section 5.4__ Power calculations for a difference of means
    * plus notes



# Critical values 

* __Critical values__ are the cutoff values that determine whether a test statistic is statistically significant or not.

```{r}
#| fig.width: 5
#| fig.height: 3
#| echo: false
cv90 <- 1.645
cv95 <- 1.96
cv99 <- 2.575

ggplot(NULL, aes(c(-3,3))) +
  geom_area(stat = "function", fun = dnorm, fill = "#00998a", alpha =0.8, xlim = c(-3, -cv99)) +
  geom_area(stat = "function", fun = dnorm, fill = "#00998a", alpha =0.6, xlim = c(-cv99, -cv95)) +
  geom_area(stat = "function", fun = dnorm, fill = "#00998a", alpha =0.4, xlim = c(-cv95, -cv90)) +
  geom_area(stat = "function", fun = dnorm, fill = "#00998a", alpha =0.1, xlim = c(-cv90, cv90)) +
  geom_area(stat = "function", fun = dnorm, fill = "#00998a", alpha =0.4, xlim = c(cv90, cv95)) +
  geom_area(stat = "function", fun = dnorm, fill = "#00998a", alpha =0.6, xlim = c(cv95, cv99)) +
  geom_area(stat = "function", fun = dnorm, fill = "#00998a", alpha =0.8, xlim = c(cv99, 3)) +
  labs(x = "z", y = "") +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = c(-cv99, -cv95, -cv90, 0, cv90, cv95, cv99)) +
  theme(axis.text.x=element_text(angle = -30, hjust = 0)) +
  annotate("text", x = -2.8, y = .1, label = ".005") +
  annotate("text", x = -2.2, y = .1, label = ".025") +
  annotate("text", x = -1.7, y = .1, label = ".05") +
  annotate("text", x = 2.8, y = .1, label = ".005") +
  annotate("text", x = 2.2, y = .1, label = ".025") +
  annotate("text", x = 1.7, y = .1, label = ".05") +
  labs(title="Critical Values for a Normal Distribution") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
```


* If a test statistic is greater in absolute value than the critical value, we reject $H_0$

* Critical values are determined by 
    * the significance level $\alpha$, 
    * whether a test is 1- or 2-sided, &
    * the probability distribution being used to calculate the p-value (such as normal or t-distribution).

* The critical values in the figure should look very familiar! 
    * Where have we used these before?

* How can we calculate the critical values using R?


## Rejection region

* If the absolute value of the test statistic is greater than the critical value, we reject $H_0$
    * In this case the test statistic is in the __rejection region__.
    * Otherwise it's in the nonrejection region.

* What do rejection regions look like for 2-sided vs. 1-sided tests?



## Hypothesis Testing "Errors" 

### Justice system analogy 

Type I and Type II Errors - Making Mistakes in the Justice System

<http://www.intuitor.com/statistics/T1T2Errors.html>


## Type I & II Errors

* [$\alpha$]{style="color:violet"} = probability of making a [__Type I error__]{style="color:violet"}
    * This is the significance level (usually 0.05)
    * Set before study starts
* [$\beta$]{style="color:green"} = probability of making a [__Type II error__]{style="color:green"}
* Ideally we want
    * small Type I & II errors and
    * big power

```{r}
#| fig.width: 6
#| fig.height: 3
#| echo: false
cv90 <- 1.645
cv95 <- 1.96
cv99 <- 2.575

ggplot(NULL, aes(c(-3,7))) +
  geom_area(stat = "function", fun = dnorm, args = list(mean=0,sd=1),fill = "violet", alpha =0.9, xlim = c(-3, -1.96)) +
    geom_area(stat = "function", fun = dnorm, args = list(mean=0,sd=1),fill = "skyblue", alpha =0.4, xlim = c(-1.96, 1.96)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean=0,sd=1),fill = "violet", alpha =0.9, xlim = c(1.96,4)) +
    geom_area(stat = "function", fun = dnorm, args = list(mean=3,sd=1),fill = "sienna1", alpha =0.7, xlim = c(-1, 1.96)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean=3,sd=1),fill = "green3", alpha =0.3, xlim = c(1.96, 6)) +
  labs(x = "", y = "", title="Type I & II errors and power") +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = c(-2, -1, 0, 1, 2, 3, 4)) +
  annotate("text", x = -3, y = .015, label = "P(Type I error)/2", hjust=0, size=3) +
  annotate("text", x = 2, y = .015, label = "P(Type I error)/2", hjust=0, size=3) +
  annotate("text", x = 3, y = .15, label = "Power", hjust=0, size=3) +
  annotate("text", x = .4, y = .05, label = "P(Type II error)", hjust=0, size=3) +
  annotate("text", x = -1, y = .3, label = "Null Population", hjust=0, size=3) +
  annotate("text", x = 2, y = .3, label = "Alternative Population", hjust=0, size=3) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
```

Applet for visualizing Type I & II errors and power: <https://rpsychologist.com/d3/NHST/>


## Relationship between Type I & II errors 

* __Type I vs. Type II error__
    * Decreasing P(Type I error) leads to 
        * increasing P(Type II error)
    * We typically keep P(Type I error) = $\alpha$ set to 0.05
        
Try out the applet at <https://rpsychologist.com/d3/NHST/>


## Relationship between Type II errors and power

<center>__Power__ = P(correctly rejecting the null hypothesis)</center>

<br>

* Also called the
    * true positive rate,
    * probability of detection, or 
    * the _sensitivity_ of a test
    

* __Power vs. Type II error__

    * Power = 1 - P(Type II error) = 1 - $\beta$

    * Thus as $\beta$ = P(Type II error) decreases, the power increases

    * P(Type II error) decreases as the mean of the alternative population gets further away from the mean of the null population (effect size gets bigger).

    * Typically want at least 80% power; 90% power is good



# Example calculating power

* Suppose the mean of the null population is 0 ( $H_0: \mu=0$ ) with standard error 1
* Find the power of a 2-sided test if the actual $\mu=3$, assuming the SE doesn't change.

```{r}
#| fig.width: 6
#| fig.height: 3
#| echo: false
cv90 <- 1.645
cv95 <- 1.96
cv99 <- 2.575

ggplot(NULL, aes(c(-3,7))) +
  geom_area(stat = "function", fun = dnorm, args = list(mean=0,sd=1),fill = "violet", alpha =0.9, xlim = c(-3, -1.96)) +
    geom_area(stat = "function", fun = dnorm, args = list(mean=0,sd=1),fill = "skyblue", alpha =0.4, xlim = c(-1.96, 1.96)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean=0,sd=1),fill = "violet", alpha =0.9, xlim = c(1.96,4)) +
    geom_area(stat = "function", fun = dnorm, args = list(mean=3,sd=1),fill = "sienna1", alpha =0.7, xlim = c(-1, 1.96)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean=3,sd=1),fill = "green3", alpha =0.3, xlim = c(1.96, 6)) +
  labs(x = "", y = "", title="Type I & II errors and power") +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = c(-2, -1, 0, 1, 2, 3, 4)) +
  annotate("text", x = -3, y = .015, label = "P(Type I error)/2", hjust=0, size=3) +
  annotate("text", x = 2, y = .015, label = "P(Type I error)/2", hjust=0, size=3) +
  annotate("text", x = 3, y = .15, label = "Power", hjust=0, size=3) +
  annotate("text", x = .4, y = .05, label = "P(Type II error)", hjust=0, size=3) +
  annotate("text", x = -1, y = .3, label = "Null Population", hjust=0, size=3) +
  annotate("text", x = 2, y = .3, label = "Alternative Population", hjust=0, size=3) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
```


* Power = $P($Reject $H_0$ when alternative pop is $N(3,1))$
* When $\alpha$ = 0.05, we reject $H_0$ when the test statistic z is at least 1.96

* Thus for $X\sim N(3,1)$ we need to calculate $P(X \le -1.96) + P(X \ge 1.96)$ :

```{r}
# left tail + right tail:
pnorm(-1.96, mean=3, sd=1, lower.tail=TRUE) + pnorm(1.96, mean=3, sd=1, lower.tail=FALSE)
```

The left tail probability `pnorm(-1.96, mean=3, sd=1, lower.tail=TRUE)` is essentially 0 in this case.

* Note that this power calculation specified the value of the SE instead of the standard deviation and sample size $n$ individually.



# Sample size calculation for testing one mean

* Recall in our body temperature example that $\mu_0=98.6$ °F and $\bar{x}= 98.25$ °F. 
    * The _p_-value from the hypothesis test was highly significant (very small).
    * What would the sample size $n$ need to be for 80% power?

* [__Calculate $n$__]{style="color:green"}, 
    * given $\alpha$, power ( $1-\beta$ ), "true" alternative mean $\mu$, and null $\mu_0$, 
    * _assuming_ the test statistic is normal (instead of t-distribution):

$$n=\left(s\frac{z_{1-\alpha/2}+z_{1-\beta}}{\mu-\mu_0}\right)^2$$

```{r}
mu <- 98.25
mu0 <- 98.6
sd <- 0.73
alpha <- 0.05
beta <- 0.20
n <- (sd*(qnorm(1-alpha/2) + qnorm(1-beta)) / (mu-mu0))^2
n
ceiling(n)  # always round UP to the next highest integer 
```


_We would only need a sample size of 35!_ However, this is an under-estimate since we used the normal instead of t-distribution.

See <http://powerandsamplesize.com/Calculators/Test-1-Mean/1-Sample-Equality>.



## Power calculation for testing one mean

Conversely, we can calculate how much power we had in our example given the sample size of 130.

* [__Calculate power__]{style="color:green"}, 
    * given $\alpha$, $n$, "true" alternative mean $\mu$, and null $\mu_0$, 
    * _assuming_ the test statistic is normal (instead of t-distribution)

$$1-\beta=
		\Phi\left(z-z_{1-\alpha/2}\right)+\Phi\left(-z-z_{1-\alpha/2}\right)
		\quad ,\quad z=\frac{\mu-\mu_0}{s/\sqrt{n}}$$

```{r}
mu <- 98.25; mu0 <- 98.6; sd <- 0.73; alpha <- 0.05; n <- 130
(z <- (mu-mu0) / (sd/sqrt(n)) )

(Power <- pnorm(z-qnorm(1-alpha/2)) + pnorm(-z-qnorm(1-alpha/2)))
```

If the population mean is 98.2 instead of 98.6, we have a 99.98% chance of correctly rejecting $H_0$ when the sample size is 130.  
We would say this was over powered.


## R package `pwr` for power analyses

* Use `pwr.t.test` for both one- and two-sample t-tests.  
* Specify all parameters _except for_ the one being solved for.

`pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,`   
`type = c("two.sample", "one.sample", "paired"),`  
`alternative = c("two.sided", "less", "greater"))`

`d` is __Cohen's d__ effect size: small = 0.2, medium = 0.5, large = 0.8

One-sample test (or paired t-test):

$$d = \frac{\mu-\mu_0}{s}$$ 

Two-sample test (independent):

$$d = \frac{\bar{x}_1 - \bar{x}_2}{s_{pooled}}$$

* $\bar{x}_1 - \bar{x}_2$ is the difference in means between the two groups that one would want to be able to detect as being significant,
* $s_{pooled}$ is the pooled SD between the two groups - often assume have same sd in each group


* R package `pwr` for basic statistical tests
    * <https://cran.r-project.org/web/packages/pwr/vignettes/pwr-vignette.html>

## `pwr`: __sample size__ for one mean test 

`pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,`   
`type = c("two.sample", "one.sample", "paired"),` 
`alternative = c("two.sided", "less", "greater"))`


* `d` is __Cohen's d__ effect size: $d = \frac{\mu-\mu_0}{s}$ 

Specify all parameters _except for_ the sample size:


```{r}
library(pwr)
t.n <- pwr.t.test(
  d = (98.6-98.25)/0.73, 
  sig.level = 0.05, 
  power = 0.80, 
  type = "one.sample")

t.n

plot(t.n)
```


## `pwr`: __power__ for one mean test 

`pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,`   
`type = c("two.sample", "one.sample", "paired"),` 
`alternative = c("two.sided", "less", "greater"))`


* `d` is __Cohen's d__ effect size: $d = \frac{\mu-\mu_0}{s}$ 

Specify all parameters _except for_ the power:

```{r}
t.power <- pwr.t.test(
  d = (98.6-98.25)/0.73, 
  sig.level = 0.05, 
  # power = 0.80, 
  n = 130,
  type = "one.sample")

t.power

plot(t.power)
```


## `pwr`: Two-sample t-test: __sample size__

`pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,`   
`type = c("two.sample", "one.sample", "paired"),` 
`alternative = c("two.sided", "less", "greater"))`

* `d` is __Cohen's d__ effect size: $d = \frac{\bar{x}_1 - \bar{x}_2}{s_{pooled}}$

__Example__: Suppose the data collected for the caffeine taps study were pilot day for a larger study. Investigators want to know what sample size they would need to detect a 2 point difference between the two groups. Assume the SD in both groups is 2.3. 

Specify all parameters _except for_ the sample size:

```{r}
t2.n <- pwr.t.test(
  d = 2/2.3, 
  sig.level = 0.05, 
  power = 0.80, 
  type = "two.sample") 

t2.n

plot(t2.n)
```


## `pwr`: Two-sample t-test: __power__

`pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,`   
`type = c("two.sample", "one.sample", "paired"),` 
`alternative = c("two.sided", "less", "greater"))`


* `d` is __Cohen's d__ effect size: $d = \frac{\bar{x}_1 - \bar{x}_2}{s_{pooled}}$

__Example__: Suppose the data collected for the caffeine taps study were pilot day for a larger study. Investigators want to know what sample size they would need to detect a 2 point difference between the two groups. Assume the SD in both groups is 2.3. 

Specify all parameters _except for_ the power:

```{r}
t2.power <- pwr.t.test(
  d = 2/2.3, 
  sig.level = 0.05, 
  # power = 0.80, 
  n = 22,
  type = "two.sample") 

t2.power

plot(t2.power)
```


## What information do we need for a power (or sample size) calculation?

There are 4 pieces of information:

1. Level of significance $\alpha$
    * Usually fixed to 0.05
1. Power
    * Ideally at least 0.80
1. Sample size
1. Effect size (expected change)

Given any 3 pieces of information, we can solve for the 4th.

```{r}
pwr.t.test(
  d = (98.6-98.25)/0.73,
  sig.level = 0.05, 
  # power = 0.80, 
  n=130,
  type = "one.sample")
```


## More software for power and sample size calculations: PASS 

* PASS is a very powerful (& expensive) software that does power and sample size calculations for many advanced statistical modeling techniques.
    * Even if you don't have access to PASS, their [documentation](https://www.ncss.com/software/pass/pass-documentation/) is very good and free online.
    * Documentation includes formulas and references.
    * PASS documentation for powering [means](https://www.ncss.com/software/pass/pass-documentation/#Means)
        * One mean, paired means, two independent means

* One-sample t-test documentation:
<https://www.ncss.com/wp-content/themes/ncss/pdf/Procedures/PASS/One-Sample_T-Tests.pdf>



# OCTRI-BERD power & sample size presentations


* __Power and Sample Size 101__
  * Presented by Meike Niederhausen; April 13, 2023
  * Slides: <http://bit.ly/PSS101-BERD-April2023>
  * [Recording](https://echo360.org/media/10f37fa6-7196-4525-bd64-6b9fcca60ac0/public)

* __Power and Sample Size for Clinical Trials: An Introduction__
  * Presented by Yiyi Chen; Feb 18, 2021
  * Slides: http://bit.ly/PSS-ClinicalTrials
  * [Recording](https://echo360.org/lesson/9a21deb8-258d-4305-bdc9-7effdc35e719/classroom)

* __Planning a Study with Power and Sample Size Considerations in Mind__
  * Presented by David Yanez; May 29, 2019
  * [Slides](https://www.ohsu.edu/sites/default/files/2019-12/PowerAndSampleSize_29MAY2019.pdf)
  * [Recording](https://echo360.org/lesson/44c9a3e9-b8ec-4042-84d8-4758cc779a1f/classroom)

* __Power and Sample Size Simulations in R__
  * Presented by Robin Baudier; Sept 21, 2023
  * [Slides](https://www.slideshare.net/ssuser84c78e/octri-pss-simulations-in-r-seminarpdf)
  * [Recording](https://echo360.org/media/12e6e603-13f9-4b50-bf76-787185acdfce/public)






